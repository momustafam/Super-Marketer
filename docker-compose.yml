services:
  # Data Warehouse SQL Server (starts first)
  data_warehouse:
    image: mcr.microsoft.com/mssql/server:2022-latest
    container_name: sql_data_warehouse
    environment:
      ACCEPT_EULA: "Y"
      SA_PASSWORD: "YourStrong!Passw0rd"
    ports:
      - "1434:1433"
    volumes:
      - sql_data_warehouse:/var/opt/mssql
      - ./data:/data  # Mount data directory for bulk loading
    healthcheck:
      test: ["CMD", "bash", "-c", "exec 3<>/dev/tcp/localhost/1433"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s
    networks:
      - app_network

  # Marketing Data Mart SQL Server (depends on warehouse)
  marketing_data_mart:
    image: mcr.microsoft.com/mssql/server:2022-latest
    container_name: sql_marketing_data_mart
    depends_on:
      data_warehouse:
        condition: service_healthy
    ports:
      - "1435:1433"
    environment:
      SA_PASSWORD: "Password1234!"
      ACCEPT_EULA: "Y"
    volumes:
      - sql_data_mart:/var/opt/mssql
    healthcheck:
      test: ["CMD", "bash", "-c", "exec 3<>/dev/tcp/localhost/1433"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s
    networks:
      - app_network

  # Combined SQL Tools for both warehouse and data mart
  sql_tools:
    image: mcr.microsoft.com/mssql-tools
    container_name: sql_tools_runner
    depends_on:
      data_warehouse:
        condition: service_healthy
      marketing_data_mart:
        condition: service_healthy
    volumes:
      - ./data_engineering/init_warehouse.sql:/scripts/init_warehouse.sql
      - ./data_engineering/init_mart.sql:/scripts/init_mart.sql
    entrypoint: >
      /bin/bash -c "
      echo 'Waiting for SQL Servers to be ready...' &&
      sleep 15 &&
      
      echo 'Running init_warehouse.sql...' &&
      /opt/mssql-tools/bin/sqlcmd -S sql_data_warehouse -U SA -P 'YourStrong!Passw0rd' -i /scripts/init_warehouse.sql 2>&1 ||
      echo 'init_warehouse.sql execution failed.' &&
      
      echo 'Waiting for Marketing Data Mart SQL Server...' &&
      for i in {1..30}; do
        /opt/mssql-tools/bin/sqlcmd -S sql_marketing_data_mart -U SA -P 'Password1234!' -Q 'SELECT 1' && break;
        sleep 2;
      done &&
      
      echo 'Running init_mart.sql...' &&
      /opt/mssql-tools/bin/sqlcmd -S sql_marketing_data_mart -U SA -P 'Password1234!' -i /scripts/init_mart.sql &&
      
      echo 'Checking if MarketingDataMart was created...' &&
      /opt/mssql-tools/bin/sqlcmd -S sql_marketing_data_mart -U SA -P 'Password1234!' -Q \"SELECT name FROM sys.databases WHERE name = 'MarketingDataMart';\" &&
      
      echo 'Initialization scripts executed successfully!';
      "
    networks:
      - app_network
  # Apache Airflow Services
  
  # PostgreSQL for Airflow metadata
  airflow_postgres:
    image: postgres:13
    container_name: airflow_postgres
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - airflow_postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 5s
      retries: 5
    networks:
      - app_network
  # Airflow Webserver
  airflow_webserver:
    build:
      context: ./airflow
      dockerfile: Dockerfile
    container_name: airflow_webserver
    depends_on:
      airflow_postgres:
        condition: service_healthy
      data_warehouse:
        condition: service_healthy
      marketing_data_mart:
        condition: service_healthy
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@airflow_postgres:5432/airflow
      AIRFLOW__CORE__FERNET_KEY: 'T5-cl7KCbawwG06ESn-5znO0KnZNrAyLyv-G4T93eO0='
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      AIRFLOW__WEBSERVER__EXPOSE_CONFIG: 'true'
      AIRFLOW__WEBSERVER__RBAC: 'false'
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./airflow/init_airflow.sh:/opt/airflow/init_airflow.sh
    ports:
      - "8080:8080"
    command: >
      bash -c "
      echo 'Starting Airflow initialization...' &&
      cp /opt/airflow/init_airflow.sh /tmp/init_airflow.sh &&
      chmod +x /tmp/init_airflow.sh &&
      /tmp/init_airflow.sh &&
      echo 'Initialization completed. Starting webserver...' &&
      airflow webserver
      "
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 10s
      timeout: 10s
      retries: 5
    networks:
      - app_network

  # Airflow Scheduler
  airflow_scheduler:
    build:
      context: ./airflow
      dockerfile: Dockerfile
    container_name: airflow_scheduler
    depends_on:
      airflow_webserver:
        condition: service_healthy
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@airflow_postgres:5432/airflow
      AIRFLOW__CORE__FERNET_KEY: 'T5-cl7KCbawwG06ESn-5znO0KnZNrAyLyv-G4T93eO0='
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./airflow/init_airflow.sh:/opt/airflow/init_airflow.sh
    command: scheduler
    networks:
      - app_network

  # FastAPI Backend
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: backend_api
    ports:
      - "8000:8000"
    environment:
      DB_SERVER: marketing_data_mart
      DB_PORT: 1433
      DB_NAME: MarketingDataMart
      DB_USER: sa
      DB_PASSWORD: Password1234!
    depends_on:
      marketing_data_mart:
        condition: service_healthy
    networks:
      - app_network

  # React Frontend
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: frontend_app
    ports:
      - "3000:3000"
    depends_on:
      - backend
      - chatbot_backend
    networks:
      - app_network

  # Chatbot Backend (separate from main backend)
  chatbot_backend:
    build:
      context: ./chatbot_backend
      dockerfile: Dockerfile
    container_name: chatbot_backend
    ports:
      - "8001:8001"
    volumes:
      - chatbot_db:/data  # Mount the SQLite database volume
    environment:
      - DATABASE_PATH=/data/chatbot.db
    depends_on:
      - chatbot_database
    networks:
      - app_network

  # Chatbot SQLite database (initializes DB from SQL file and keeps container running)
  chatbot_database:
    image: alpine:latest
    container_name: chatbot_database
    volumes:
      - chatbot_db:/data
      - ./data_engineering/init_chatbot.sql:/scripts/init_chatbot.sql:ro
    # Initialize the sqlite DB on first start and keep the container alive so the DB file persists
    command: >
      /bin/sh -c "apk add --no-cache sqlite && mkdir -p /data && if [ ! -f /data/chatbot.db ]; then echo 'Initializing chatbot.db from SQL...' && sqlite3 /data/chatbot.db < /scripts/init_chatbot.sql; fi && echo 'Initialization check - tables:' && sqlite3 /data/chatbot.db \"SELECT name FROM sqlite_master WHERE type='table';\" || true && echo 'Initialization check - .tables output:' && sqlite3 /data/chatbot.db '.tables' || true && tail -f /dev/null"
    networks:
      - app_network

volumes:
  sql_data_warehouse:
  sql_data_mart:
  airflow_postgres_data:
  chatbot_db:

networks:
  app_network:
    name: super_marketer_network
    driver: bridge